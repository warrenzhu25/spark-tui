{"Event":"SparkListenerApplicationStart","App Name":"OOM Test Application","App ID":"app-20241201140000-0001","Timestamp":1733059200000,"User":"testuser","Spark Version":"3.5.0"}
{"Event":"SparkListenerEnvironmentUpdate","Spark Properties":{"spark.app.name":"OOM Test Application","spark.executor.memory":"1g","spark.executor.cores":"2","spark.sql.adaptive.enabled":"false","spark.serializer":"org.apache.spark.serializer.KryoSerializer","spark.executor.memoryFraction":"0.8","spark.storage.memoryFraction":"0.6"},"System Properties":{"java.version":"11.0.16","user.name":"testuser","os.name":"Linux","java.runtime.version":"11.0.16+8-post-Ubuntu-0ubuntu120.04"},"Hadoop Properties":{"hadoop.version":"3.2.2"},"Classpath Entries":{}}
{"Event":"SparkListenerExecutorAdded","Executor ID":"driver","Executor Info":{"Host":"driver-node","Total Cores":4,"Maximum Memory":536870912},"Timestamp":1733059201000}
{"Event":"SparkListenerExecutorAdded","Executor ID":"1","Executor Info":{"Host":"worker1","Total Cores":2,"Maximum Memory":1073741824},"Timestamp":1733059202000}
{"Event":"SparkListenerExecutorAdded","Executor ID":"2","Executor Info":{"Host":"worker2","Total Cores":2,"Maximum Memory":1073741824},"Timestamp":1733059203000}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1733059205000,"Stage IDs":[0],"Properties":{"spark.job.description":"Large dataset aggregation"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"groupByKey at Main.scala:42","Number of Tasks":200,"Submission Time":1733059205100,"Parent IDs":[],"RDD Info":[{"RDD ID":0,"Name":"MapPartitionsRDD","Number of Partitions":200,"Storage Level":"MEMORY_AND_DISK_SER","Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"ShuffledRDD","Number of Partitions":200,"Storage Level":"NONE","Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}]}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":0,"Launch Time":1733059205200,"Executor ID":"1","Host":"worker1"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":1,"Launch Time":1733059205250,"Executor ID":"1","Host":"worker1"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":2,"Launch Time":1733059205300,"Executor ID":"2","Host":"worker2"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":3,"Launch Time":1733059205350,"Executor ID":"2","Host":"worker2"}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":0,"Launch Time":1733059205200,"Finish Time":1733059208500,"Executor ID":"1","Host":"worker1","Finished":true},"Task Metrics":{"Executor Run Time":3200,"Executor CPU Time":2800,"JVM GC Time":1200,"Result Size":2048,"Memory Bytes Spilled":524288000,"Disk Bytes Spilled":104857600,"Peak Execution Memory":805306368,"Shuffle Write Metrics":{"Bytes Written":157286400,"Write Time":450000,"Records Written":1000000}}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"java.lang.OutOfMemoryError","Description":"Java heap space","Stack Trace":[{"Declaring Class":"java.util.Arrays","Method Name":"copyOf","File Name":"Arrays.java","Line Number":3332},{"Declaring Class":"java.util.ArrayList","Method Name":"grow","File Name":"ArrayList.java","Line Number":237},{"Declaring Class":"org.apache.spark.util.collection.AppendOnlyMap","Method Name":"growTable","File Name":"AppendOnlyMap.scala","Line Number":144}],"Full Stack Trace":"java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOf(Arrays.java:3332)\n\tat java.util.ArrayList.grow(ArrayList.java:237)\n\tat org.apache.spark.util.collection.AppendOnlyMap.growTable(AppendOnlyMap.scala:144)","Accumulator Updates":[]},"Task Info":{"Task ID":1,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":1,"Launch Time":1733059205250,"Finish Time":1733059209800,"Executor ID":"1","Host":"worker1","Failed":true},"Task Metrics":{"Executor Run Time":4550,"Executor CPU Time":3200,"JVM GC Time":2800,"Result Size":0,"Memory Bytes Spilled":1073741824,"Disk Bytes Spilled":0,"Peak Execution Memory":1073741824}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":1,"Launch Time":1733059210000,"Executor ID":"2","Host":"worker2"}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":2,"Launch Time":1733059205300,"Finish Time":1733059211200,"Executor ID":"2","Host":"worker2","Finished":true},"Task Metrics":{"Executor Run Time":5900,"Executor CPU Time":4200,"JVM GC Time":1800,"Result Size":2048,"Memory Bytes Spilled":262144000,"Disk Bytes Spilled":52428800,"Peak Execution Memory":671088640,"Shuffle Write Metrics":{"Bytes Written":104857600,"Write Time":320000,"Records Written":800000}}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"java.lang.OutOfMemoryError","Description":"GC overhead limit exceeded","Stack Trace":[{"Declaring Class":"org.apache.spark.util.collection.ExternalSorter","Method Name":"spill","File Name":"ExternalSorter.scala","Line Number":220},{"Declaring Class":"org.apache.spark.util.collection.Spillable","Method Name":"maybeSpill","File Name":"Spillable.scala","Line Number":107}],"Full Stack Trace":"java.lang.OutOfMemoryError: GC overhead limit exceeded\n\tat org.apache.spark.util.collection.ExternalSorter.spill(ExternalSorter.scala:220)\n\tat org.apache.spark.util.collection.Spillable.maybeSpill(Spillable.scala:107)","Accumulator Updates":[]},"Task Info":{"Task ID":3,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":3,"Launch Time":1733059205350,"Finish Time":1733059212500,"Executor ID":"2","Host":"worker2","Failed":true},"Task Metrics":{"Executor Run Time":7150,"Executor CPU Time":2100,"JVM GC Time":4800,"Result Size":0,"Memory Bytes Spilled":2147483648,"Disk Bytes Spilled":0,"Peak Execution Memory":1073741824}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":3,"Launch Time":1733059212700,"Executor ID":"1","Host":"worker1"}}
{"Event":"SparkListenerExecutorRemoved","Executor ID":"1","Removed Reason":"Command exited with code 1","Timestamp":1733059213000}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExecutorLostFailure","Executor ID":"1","Exit Caused By App":true,"Reason":"Command exited with code 1"},"Task Info":{"Task ID":4,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":1,"Launch Time":1733059210000,"Finish Time":1733059213100,"Executor ID":"2","Host":"worker2","Failed":true},"Task Metrics":null}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExecutorLostFailure","Executor ID":"1","Exit Caused By App":true,"Reason":"Command exited with code 1"},"Task Info":{"Task ID":5,"Stage ID":0,"Stage Attempt ID":0,"Partition ID":3,"Launch Time":1733059212700,"Finish Time":1733059213100,"Executor ID":"1","Host":"worker1","Failed":true},"Task Metrics":null}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"groupByKey at Main.scala:42","Number of Tasks":200,"Submission Time":1733059205100,"Completion Time":1733059213200,"Parent IDs":[],"RDD Info":[{"RDD ID":0,"Name":"MapPartitionsRDD","Number of Partitions":200,"Storage Level":"MEMORY_AND_DISK_SER","Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":1,"Name":"ShuffledRDD","Number of Partitions":200,"Storage Level":"NONE","Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Failure Reason":"Job aborted due to stage failure: Task failed 3 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, worker1, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Command exited with code 1"}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1733059213300,"Job Result":{"Result":"JobFailed","Exception":{"Message":"Job aborted due to stage failure: Task failed 3 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5, worker1, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Command exited with code 1","Stack Trace":"org.apache.spark.SparkException: Job aborted due to stage failure"}}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1733059213500}